---
title: "Questions"
author: "Spiro Stilianoudakis"
date: "8/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Document containing questions and answers

## Jul 30, 2020 Saagar Sheth

### Question

I'm a little confused as to what the input and output dimensions are for the neural network. 

What would the input_dim be and the output_dim as well? For the history function, are there any specifications on the batch_size for your code? Also, how should I split validation_split? You did chromosome 22, but I'm not sure how to replicate that with a neural network. 

model <- keras_model_sequential() %>%
  layer_embedding(input_dim = 64, output_dim = 32) %>%
  layer_simple_rnn(units = 32) %>%
  layer_dense(units = 1, activation = "sigmoid")
model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("acc")
)
history <- model %>% fit(
  input_train, y_train,
  epochs = 10,
  batch_size = 128,
  validation_split = 0.2
)

plot(history)

### Answer

I would skip to looking specifically at LSTM (subset of RNNs). Simply RNNs are good for sequence/text data, not great for the type of 2D data we have here. That is why there is layer_embedding part there. This is not necessary for our problem. Look at pg 191 of the text.

One thing to consider first:

   * After reading more into LSTM myself, it is necessary for the rows of the data to be dependent on the previous row (as is the case with time series data). For this, we need to specify `resampling="none"` in the `preciseTAD::createTADdata` function (the function that creates your training and testing data sets). This assures us that no resampling or shuffling of data occurs. 
   
Regarding the question about batch_size, no there is no specification. It has to be played around with. Larger values require more memory to be stored in R, smaller values give less precise results.

For validation_split, it means how much of the training data is reserved for validation. In my example CHR22 was used for testing, not validation. If validation_split = 0.2, 20% of the training is used to validate, prior to testing

Below is a potential example of an LSTM in our case (code hasn't been ran, so test it out and let me know how it goes):

```{r}
library(keras)
library(preciseTAD)

#Getting training and testing data 
data("tfbsList")

domains <- read.table("./data/arrowhead_data/50kb/GM12878_domain_data_50000.b.txt", header=F)

bounds.GR <- preciseTAD::extractBoundaries(domains.mat=domains, 
                                     preprocess=FALSE, 
                                     CHR=paste0("CHR", c(1:8,10:22)), 
                                     resolution=50000)

tadData_distance <- preciseTAD::createTADdata(bounds.GR=bounds.GR, 
                                  resolution=50000, 
                                  genomicElements.GR=tfbsList, 
                                  featureType="distance", 
                                  resampling="none", 
                                  trainCHR=paste0("CHR",c(1:8,10:21)), 
                                  predictCHR="CHR22") 

#lets concatenate the training and testing into one data matrix
all_tad_data <- rbind.data.frame(tadData_distance[[1]], tadData_distance[[2]], stringsAsFactors = FALSE)
all_tad_data <- data.matrix(all_tad_data)
all_tad_data[,1] <- all_tad_data[,1]-1

#set up the generator function (see pg 194)
generator <- function(data, lookback, delay, min_index, max_index,
                      shuffle = FALSE, batch_size = 128, step = 6) {
  if (is.null(max_index))
    max_index <- nrow(data) - delay - 1
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } else {
      if (i + batch_size >= max_index)
        i <<- min_index + lookback
      rows <- c(i:min(i+batch_size-1, max_index))
      i <<- i + length(rows)
    }

    samples <- array(0, dim = c(length(rows),
                                lookback / step,
                                dim(data)[[-1]]))
    targets <- array(0, dim = c(length(rows)))
                      
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback, rows[[j]]-1,
                     length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,]
      targets[[j]] <- data[rows[[j]] + delay,2]
    }           
    list(samples, targets)
  }
}

#setting parameters for the generator function
lookback <- 50 #observations will go back 50 bins (each bin is 50kb in width -> for 50*50000=2500000 bases)
step <- 1 #Observations will be sampled at one data point per bin (50000 bases)
delay <- 10 #Targets will be 10 bins (10*50000=500000 bases) in the future.
batch_size <- 128 #The number of samples per batch

#assigning 3 generator functions for training, validation, and testing
train_gen <- generator(
  all_tad_data,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = 42561,
  shuffle = FALSE,
  step = step, 
  batch_size = batch_size
)

val_gen = generator(
  all_tad_data,
  lookback = lookback,
  delay = delay,
  min_index = 42562,
  max_index = 52561,
  step = step,
  batch_size = batch_size
)

test_gen <- generator(
  all_tad_data,
  lookback = lookback,
  delay = delay,
  min_index = 52562,
  max_index = NULL,
  step = step,
  batch_size = batch_size
)

# How many steps to draw from val_gen in order to see the entire validation set
val_steps <- (52561 - 42562 - lookback) / batch_size

# How many steps to draw from test_gen in order to see the entire test set
test_steps <- (nrow(all_tad_data) - 52561 - lookback) / batch_size

model <- keras_model_sequential() %>%
    layer_lstm(units = 10, input_shape = c(50, 26)) %>%
    layer_dense(units = 10, activation = "relu") %>%
    layer_dense(units = 5, activation = "relu") %>%
    layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
    optimizer = "rmsprop",
    loss = "binary_crossentropy",
    metrics = c("accuracy")
)

history <- model %>% fit_generator(
  train_gen,
  steps_per_epoch = 20,
  epochs = 5,
  validation_data = val_gen,
  validation_steps = val_steps
)

plot(history)

pred <- model %>% predict(all_tad_data[52562:53527,-1])
pred <- ifelse(pred < .5,0,1)

table(pred, all_tad_data[52562:53527,1])
```


